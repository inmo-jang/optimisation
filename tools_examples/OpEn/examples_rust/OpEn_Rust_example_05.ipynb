{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpEn Rust Usage Example 05\n",
    "\n",
    "This example follows [Example 04](https://github.com/inmo-jang/optimisation_tutorial/blob/master/tools_examples/OpEn/examples_rust/OpEn_Rust_example_04.ipynb). \n",
    "\n",
    "In the previous example, we used the given cost function itself as an additional constraint. Here, we are just trying to solve the optimisation problem as it is. \n",
    "\n",
    "\n",
    "## Reminder \n",
    "\n",
    "- The ALM/PM solver of OpEn can address more general problems that involve constraints of the general form $F_1(u) \\in C$ and $F_2(u) = 0$. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "For rust implementation in Jupyter notebook, we need to import \"optimization_engine\"\n",
    "- In your local PC, it should be also declared in \"Cargo.toml\".\n",
    "- In this jupyter notebook, we need to have \"extern crate\" as follows. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "extern crate optimization_engine;\n",
    "use optimization_engine::{\n",
    "    alm::*,\n",
    "    constraints::*, panoc::*, *\n",
    "};"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Formulation\n",
    "\n",
    "What we are going to solve is as follows: \n",
    "\n",
    "Minimise  $$f(u) = \\frac{1}{2} ( u_1^2 + u_2^2) $$\n",
    "\n",
    "subject to\n",
    "\n",
    "$$2 u_1 -  u_3 + 1 = 0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective Function\n",
    "\n",
    "Suppose that\n",
    "$$f(u) = \\frac{1}{2} ( u_1^2 + u_2^2) $$\n",
    "\n",
    "with gradient\n",
    "\n",
    "$$\\nabla f(u) = [ u_1 , u_2, 0 ] $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pub fn f(u: &[f64], cost: &mut f64) -> Result<(), SolverError> {\n",
    "    *cost = 0.5 * (u[0].powi(2)+u[1].powi(2));\n",
    "    Ok(())\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pub fn df(u: &[f64], grad: &mut [f64]) -> Result<(), SolverError> {\n",
    "    grad[0] = u[0];\n",
    "    grad[1] = u[1];\n",
    "    grad[2] = 0.0;  \n",
    "    Ok(())\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constraints\n",
    "\n",
    "We impose a constraint:\n",
    "\n",
    "$$F_1(u) \\in C$$\n",
    "where \n",
    "$$F_1(u) = 2 u_1 -  u_3 + 1$$\n",
    "\n",
    "\n",
    "\n",
    "$$C = \\{0 \\}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pub fn f1(u: &[f64], f1u: &mut [f64]) -> Result<(), SolverError> {\n",
    "    f1u[0] = 2.0*u[0] - u[2] + 1.0;\n",
    "    Ok(())\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to define Jacobian product:\n",
    "\n",
    "$$JF_1^{\\top} \\cdot d = \n",
    "\\begin{bmatrix}\n",
    "2 d_1\\\\\n",
    "0 \\\\\n",
    "-d_1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "where $J F_1$ is the Jacobian matrix of $F_1$ for given vectors $u \\in \\mathbb{R}^3$ (decision variables) and $d \\in \\mathbb{R}^1$ (dimension of constraints).\n",
    "\n",
    "NOTE:\n",
    "\n",
    "$$JF_1 = \\begin{bmatrix}\n",
    "\\frac{\\partial F_{1}}{\\partial u_1} & \\frac{\\partial F_{1}}{\\partial u_2} & \\frac{\\partial F_{1}}{\\partial u_3} \n",
    "\\end{bmatrix}\n",
    "=\n",
    " \\begin{bmatrix}\n",
    "2 & 0 & -1\n",
    "\\end{bmatrix}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pub fn f1_jacobian_product(u: &[f64], d: &[f64], res: &mut [f64]) -> Result<(), SolverError> {\n",
    "    res[0] = 2.0*d[0];\n",
    "    res[1] = 0.0;\n",
    "    res[2] = -d[0];\n",
    "    Ok(())\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the problem we need to solve is\n",
    "\n",
    "$$\\text{Minimise} f(u)$$\n",
    "$$\\text{subject to } -100 \\le u_i \\le 100 \\text{  for all $i$}$$\n",
    "$$F_1(u,p) \\in C$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invoking the main function\n",
    "\n",
    "#### `AlmFactory` \n",
    "- construct $\\psi$ and its gradient\n",
    "- [Input structure](https://docs.rs/optimization_engine/0.6.2/src/optimization_engine/alm/alm_factory.rs.html#150-186) shoud be\n",
    "\n",
    "```\n",
    "pub fn new(\n",
    "    f: Cost,\n",
    "    df: CostGradient,\n",
    "    mapping_f1: Option<MappingF1>,\n",
    "    jacobian_mapping_f1_trans: Option<JacobianMappingF1Trans>,\n",
    "    mapping_f2: Option<MappingF2>,\n",
    "    jacobian_mapping_f2_trans: Option<JacobianMappingF2Trans>,\n",
    "    set_c: Option<SetC>,\n",
    "    n2: usize,\n",
    ")\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "fn main() {\n",
    "    let tolerance = 1e-5;\n",
    "    let nx = 3; // problem_size: dimension of the decision variables\n",
    "    let n1 = 1; // range dimensions of mappings F1\n",
    "    let n2 = 0; // range dimensions of mappings F2\n",
    "    let lbfgs_mem = 5; // memory of the LBFGS buffer\n",
    "    \n",
    "    // PANOCCache: All the information needed at every step of the algorithm\n",
    "    let panoc_cache = PANOCCache::new(nx, tolerance, lbfgs_mem);\n",
    "    \n",
    "    // AlmCache: A cache structure that contains all the data \n",
    "    // that make up the state of the ALM/PM algorithm\n",
    "    // (i.e., all those data that the algorithm updates)\n",
    "    let mut alm_cache = AlmCache::new(panoc_cache, n1, n2);\n",
    "\n",
    "    let set_c = Zero::new(); // Set C\n",
    "    let bounds = Ball2::new(None, 100.0); // Set U\n",
    "    let set_y = Ball2::new(None, 1e12);  // Set Y\n",
    "\n",
    "    // AlmFactory: Prepare function psi and its gradient \n",
    "    // given the problem data such as f, del_f and \n",
    "    // optionally F_1, JF_1, C, F_2\n",
    "    let factory = AlmFactory::new(\n",
    "        f, // Cost function\n",
    "        df, // Cost Gradient\n",
    "        Some(f1), // MappingF1\n",
    "        Some(f1_jacobian_product), // Jacobian Mapping F1 Trans\n",
    "        NO_MAPPING, // MappingF2\n",
    "        NO_JACOBIAN_MAPPING, // Jacobian Mapping F2 Trans\n",
    "        Some(set_c), // Constraint set\n",
    "        n2,\n",
    "    );\n",
    "\n",
    "    // Define an optimisation problem \n",
    "    // to be solved with AlmOptimizer\n",
    "    let alm_problem = AlmProblem::new(\n",
    "        bounds,\n",
    "        Some(set_c),\n",
    "        Some(set_y),\n",
    "        |u: &[f64], xi: &[f64], cost: &mut f64| -> Result<(), SolverError> {\n",
    "            factory.psi(u, xi, cost)\n",
    "        },\n",
    "        |u: &[f64], xi: &[f64], grad: &mut [f64]| -> Result<(), SolverError> {\n",
    "            factory.d_psi(u, xi, grad)\n",
    "        },\n",
    "        Some(f1),\n",
    "        NO_MAPPING,\n",
    "        n1,\n",
    "        n2,\n",
    "    );\n",
    "\n",
    "    let mut alm_optimizer = AlmOptimizer::new(&mut alm_cache, alm_problem)\n",
    "        .with_delta_tolerance(1e-5)\n",
    "        .with_max_outer_iterations(200)\n",
    "        .with_epsilon_tolerance(1e-6)\n",
    "        .with_initial_inner_tolerance(1e-2)\n",
    "        .with_inner_tolerance_update_factor(0.5)\n",
    "        .with_initial_penalty(100.0)\n",
    "        .with_penalty_update_factor(1.05)\n",
    "        .with_sufficient_decrease_coefficient(0.2)\n",
    "        .with_initial_lagrange_multipliers(&vec![5.0; n1]);\n",
    "\n",
    "    let mut u = vec![0.0; nx];\n",
    "    let solver_result = alm_optimizer.solve(&mut u);\n",
    "    let r = solver_result.unwrap();\n",
    "    println!(\"\\n\\nSolver result : {:#.7?}\\n\", r);\n",
    "    println!(\"Solution u = {:#.6?}\", u);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's excute it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Solver result : AlmOptimizerStatus {\n",
      "    exit_status: Converged,\n",
      "    num_outer_iterations: 15,\n",
      "    num_inner_iterations: 506,\n",
      "    last_problem_norm_fpr: 0.0000008,\n",
      "    lagrange_multipliers: Some(\n",
      "        [\n",
      "            0.0009983,\n",
      "        ],\n",
      "    ),\n",
      "    solve_time: 209.8380000µs,\n",
      "    penalty: 171.0339358,\n",
      "    delta_y_norm: 0.0001620,\n",
      "    f2_norm: 0.0000000,\n",
      "}\n",
      "\n",
      "Solution u = [\n",
      "    -0.002094,\n",
      "    0.000000,\n",
      "    0.995811,\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "main();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This example is wrong\n",
    "\n",
    "As you see above, the result is different from the previous example, where the solution was $u = [-0.44949, 0.0, 0.101021]$. \n",
    "\n",
    "**IMPORTANT:** It seems that we should have had the additional constraint as we did in Example 04. Let's do it like that again. \n",
    "\n",
    "Let's copy `f1` and `f1_jacobian_product` from the previous example. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pub fn f1(u: &[f64], f1u: &mut [f64]) -> Result<(), SolverError> {\n",
    "    f1u[0] = 2.0*u[0] - u[2] + 1.0;\n",
    "    f1u[1] = 0.5 * (u[0].powi(2)+u[1].powi(2)) - u[2];\n",
    "    Ok(())\n",
    "}\n",
    "\n",
    "pub fn f1_jacobian_product(u: &[f64], d: &[f64], res: &mut [f64]) -> Result<(), SolverError> {\n",
    "    res[0] = 2.0*d[0] + u[0]*d[1];\n",
    "    res[1] = u[1]*d[1];\n",
    "    res[2] = -d[0] - d[1];\n",
    "    Ok(())\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the dimension of F1 is changed, we also need to redefine `main()` as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn main() {\n",
    "    let tolerance = 1e-5;\n",
    "    let nx = 3; // problem_size: dimension of the decision variables\n",
    "    let n1 = 2; // range dimensions of mappings F1\n",
    "    let n2 = 0; // range dimensions of mappings F2\n",
    "    let lbfgs_mem = 5; // memory of the LBFGS buffer\n",
    "    \n",
    "    // PANOCCache: All the information needed at every step of the algorithm\n",
    "    let panoc_cache = PANOCCache::new(nx, tolerance, lbfgs_mem);\n",
    "    \n",
    "    // AlmCache: A cache structure that contains all the data \n",
    "    // that make up the state of the ALM/PM algorithm\n",
    "    // (i.e., all those data that the algorithm updates)\n",
    "    let mut alm_cache = AlmCache::new(panoc_cache, n1, n2);\n",
    "\n",
    "    let set_c = Zero::new(); // Set C\n",
    "    let bounds = Ball2::new(None, 100.0); // Set U\n",
    "    let set_y = Ball2::new(None, 1e12);  // Set Y\n",
    "\n",
    "    // AlmFactory: Prepare function psi and its gradient \n",
    "    // given the problem data such as f, del_f and \n",
    "    // optionally F_1, JF_1, C, F_2\n",
    "    let factory = AlmFactory::new(\n",
    "        f, // Cost function\n",
    "        df, // Cost Gradient\n",
    "        Some(f1), // MappingF1\n",
    "        Some(f1_jacobian_product), // Jacobian Mapping F1 Trans\n",
    "        NO_MAPPING, // MappingF2\n",
    "        NO_JACOBIAN_MAPPING, // Jacobian Mapping F2 Trans\n",
    "        Some(set_c), // Constraint set\n",
    "        n2,\n",
    "    );\n",
    "\n",
    "    // Define an optimisation problem \n",
    "    // to be solved with AlmOptimizer\n",
    "    let alm_problem = AlmProblem::new(\n",
    "        bounds,\n",
    "        Some(set_c),\n",
    "        Some(set_y),\n",
    "        |u: &[f64], xi: &[f64], cost: &mut f64| -> Result<(), SolverError> {\n",
    "            factory.psi(u, xi, cost)\n",
    "        },\n",
    "        |u: &[f64], xi: &[f64], grad: &mut [f64]| -> Result<(), SolverError> {\n",
    "            factory.d_psi(u, xi, grad)\n",
    "        },\n",
    "        Some(f1),\n",
    "        NO_MAPPING,\n",
    "        n1,\n",
    "        n2,\n",
    "    );\n",
    "\n",
    "    let mut alm_optimizer = AlmOptimizer::new(&mut alm_cache, alm_problem)\n",
    "        .with_delta_tolerance(1e-5)\n",
    "        .with_max_outer_iterations(200)\n",
    "        .with_epsilon_tolerance(1e-6)\n",
    "        .with_initial_inner_tolerance(1e-2)\n",
    "        .with_inner_tolerance_update_factor(0.5)\n",
    "        .with_initial_penalty(100.0)\n",
    "        .with_penalty_update_factor(1.05)\n",
    "        .with_sufficient_decrease_coefficient(0.2)\n",
    "        .with_initial_lagrange_multipliers(&vec![5.0; n1]);\n",
    "\n",
    "    let mut u = vec![0.0; nx];\n",
    "    let solver_result = alm_optimizer.solve(&mut u);\n",
    "    let r = solver_result.unwrap();\n",
    "    println!(\"\\n\\nSolver result : {:#.7?}\\n\", r);\n",
    "    println!(\"Solution u = {:#.6?}\", u);\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Solver result : AlmOptimizerStatus {\n",
      "    exit_status: Converged,\n",
      "    num_outer_iterations: 15,\n",
      "    num_inner_iterations: 80,\n",
      "    last_problem_norm_fpr: 0.0000001,\n",
      "    lagrange_multipliers: Some(\n",
      "        [\n",
      "            0.1834754,\n",
      "            -0.1835201,\n",
      "        ],\n",
      "    ),\n",
      "    solve_time: 163.7220000µs,\n",
      "    penalty: 155.1328216,\n",
      "    delta_y_norm: 0.0002070,\n",
      "    f2_norm: 0.0000000,\n",
      "}\n",
      "\n",
      "Solution u = [\n",
      "    -0.449490,\n",
      "    0.000000,\n",
      "    0.101021,\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "main();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison with Example 04\n",
    "\n",
    "- The outcome is the same.\n",
    "- But, `solve_time` is 1.5 times higher (NB: it was 103 micro secs; and 50 of inner iterations). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "_draft": {
   "nbviewer_url": "https://gist.github.com/4f1590278592d1039147b01c055c21ca"
  },
  "gist": {
   "data": {
    "description": "home/inmo/Jupyter/OpEn_Rust_example.ipynb",
    "public": true
   },
   "id": "4f1590278592d1039147b01c055c21ca"
  },
  "kernelspec": {
   "display_name": "Rust",
   "language": "rust",
   "name": "rust"
  },
  "language_info": {
   "codemirror_mode": "rust",
   "file_extension": ".rs",
   "mimetype": "text/rust",
   "name": "Rust",
   "pygment_lexer": "rust",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
